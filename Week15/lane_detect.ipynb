{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实验：车道线检测\n",
    "\n",
    "## 一、实验内容\n",
    "基于机器视觉对交通车道线进行实时检测，应用全卷积神经网络对车道线进行识别和定位，并对车道线识别结果进行可视化。\n",
    "\n",
    "## 二、实验目标\n",
    "1. 了解全卷积神经网络基本原理\n",
    "2. 熟悉车道线检测的常规流程\n",
    "3. 掌握车道线检测模型的使用方法\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、实验过程\n",
    "\n",
    "\n",
    "### 3.0 数据集预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using MoXing-v1.17.3-43fbf97f\n",
      "INFO:root:Using OBS-Python-SDK-3.20.7\n"
     ]
    }
   ],
   "source": [
    "import moxing as mox\n",
    "mox.file.copy_parallel(\"s3://obs-22spring/20181016_deepLearn/full_CNN_train.p\",\"./full_CNN_train.p\")\n",
    "mox.file.copy_parallel(\"s3://obs-22spring/20181016_deepLearn/full_CNN_labels.p\",\"./full_CNN_labels.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle as pl\n",
    "import cv2\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "\n",
    "def arrayShow(imageArray):\n",
    "    ret, jpg = cv2.imencode('.jpg', imageArray)\n",
    "    return Image(jpg)\n",
    "\n",
    "#fr = open('full_CNN_train.p','rb')\n",
    "fr = open('full_CNN_labels.p','rb')\n",
    "images = pl.load(fr)\n",
    "fr.close()\n",
    "\n",
    "for img in images:\n",
    "    clear_output(wait=True)\n",
    "    display(arrayShow(img))\n",
    "    k = cv2.waitKey(100)\n",
    "    if( k & 0xff == ord('q')):\n",
    "        break\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(len(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 模型训练\n",
    "\n",
    "首先导入需要的组件包，Numpy、keras、sklearn等，代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ma-user/anaconda3/envs/TensorFlow-1.13-gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ma-user/anaconda3/envs/TensorFlow-1.13-gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ma-user/anaconda3/envs/TensorFlow-1.13-gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ma-user/anaconda3/envs/TensorFlow-1.13-gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ma-user/anaconda3/envs/TensorFlow-1.13-gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ma-user/anaconda3/envs/TensorFlow-1.13-gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import necessary items from Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, UpSampling2D\n",
    "from keras.layers import Conv2DTranspose, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import regularizers\n",
    "\n",
    "#https://github.com/mvirgo/MLND-Capstone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1)模型结构定义\n",
    "网络输入层为80 x 160 x 3（RGB）形状的道路图像，标签为80 x 160 x 1，只有G通道重新绘制车道，实现代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, pool_size):\n",
    "    # 创建网络模型\n",
    "    model = Sequential()\n",
    "    # 对输入层进行归一化处理\n",
    "    model.add(BatchNormalization(input_shape=input_shape))\n",
    "\n",
    "    # 卷积层1，名为Conv1\n",
    "    model.add(Conv2D(8, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv1'))\n",
    "\n",
    "    # 卷积层2\n",
    "    model.add(Conv2D(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv2'))\n",
    "\n",
    "    # 最大化层\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    # 卷积层3\n",
    "    model.add(Conv2D(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv3'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # 卷积层4\n",
    "    model.add(Conv2D(32, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv4'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # 卷积层5\n",
    "    model.add(Conv2D(32, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv5'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # 最大化层2\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    # 卷积层6\n",
    "    model.add(Conv2D(64, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv6'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # 卷积层7\n",
    "    model.add(Conv2D(64, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Conv7'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # 最大化层3\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    # 上采样层1\n",
    "    model.add(UpSampling2D(size=pool_size))\n",
    "\n",
    "    # 反卷积层 1\n",
    "    model.add(Conv2DTranspose(64, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv1'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # 反卷积层 2\n",
    "    model.add(Conv2DTranspose(64, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv2'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # 上采样层 2\n",
    "    model.add(UpSampling2D(size=pool_size))\n",
    "\n",
    "    # 反卷积层 3\n",
    "    model.add(Conv2DTranspose(32, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv3'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # 反卷积层 4\n",
    "    model.add(Conv2DTranspose(32, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv4'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # 反卷积层 5\n",
    "    model.add(Conv2DTranspose(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv5'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # 上采样层 3\n",
    "    model.add(UpSampling2D(size=pool_size))\n",
    "\n",
    "    # 反卷积层 6\n",
    "    model.add(Conv2DTranspose(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Deconv6'))\n",
    "\n",
    "    # 输出层\n",
    "    model.add(Conv2DTranspose(1, (3, 3), padding='valid', strides=(1,1), activation = 'relu', name = 'Final'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2）加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded train samples: 12764\n"
     ]
    }
   ],
   "source": [
    "# 加载训练数据\n",
    "train_images = pickle.load(open(\"full_CNN_train.p\", \"rb\" ))\n",
    "\n",
    "# 加载标签数据\n",
    "labels = pickle.load(open(\"full_CNN_labels.p\", \"rb\" ))\n",
    "\n",
    "# 对数据进行预处理\n",
    "train_images = np.array(train_images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# 对标签进行归一化处理\n",
    "labels = labels / 255\n",
    "\n",
    "# 混淆数据\n",
    "train_images, labels = shuffle(train_images, labels)\n",
    "# 划分训练集和测试集\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_images, labels, test_size=0.1)\n",
    "\n",
    "print(\"loaded train samples:\", len(train_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3）构建并编译模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ma-user/anaconda3/envs/TensorFlow-1.13-gpu/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ma-user/anaconda3/envs/TensorFlow-1.13-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_1 (Batch (None, 80, 160, 3)        12        \n",
      "_________________________________________________________________\n",
      "Conv1 (Conv2D)               (None, 78, 158, 8)        224       \n",
      "_________________________________________________________________\n",
      "Conv2 (Conv2D)               (None, 76, 156, 16)       1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 38, 78, 16)        0         \n",
      "_________________________________________________________________\n",
      "Conv3 (Conv2D)               (None, 36, 76, 16)        2320      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 36, 76, 16)        0         \n",
      "_________________________________________________________________\n",
      "Conv4 (Conv2D)               (None, 34, 74, 32)        4640      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 34, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "Conv5 (Conv2D)               (None, 32, 72, 32)        9248      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32, 72, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "Conv6 (Conv2D)               (None, 14, 34, 64)        18496     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 14, 34, 64)        0         \n",
      "_________________________________________________________________\n",
      "Conv7 (Conv2D)               (None, 12, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 12, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 16, 64)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 12, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "Deconv1 (Conv2DTranspose)    (None, 14, 34, 64)        36928     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 14, 34, 64)        0         \n",
      "_________________________________________________________________\n",
      "Deconv2 (Conv2DTranspose)    (None, 16, 36, 64)        36928     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 16, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 32, 72, 64)        0         \n",
      "_________________________________________________________________\n",
      "Deconv3 (Conv2DTranspose)    (None, 34, 74, 32)        18464     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 34, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "Deconv4 (Conv2DTranspose)    (None, 36, 76, 32)        9248      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 36, 76, 32)        0         \n",
      "_________________________________________________________________\n",
      "Deconv5 (Conv2DTranspose)    (None, 38, 78, 16)        4624      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 38, 78, 16)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 76, 156, 16)       0         \n",
      "_________________________________________________________________\n",
      "Deconv6 (Conv2DTranspose)    (None, 78, 158, 16)       2320      \n",
      "_________________________________________________________________\n",
      "Final (Conv2DTranspose)      (None, 80, 160, 1)        145       \n",
      "=================================================================\n",
      "Total params: 181,693\n",
      "Trainable params: 181,687\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 定义超参\n",
    "#批大小\n",
    "batch_size = 128\n",
    "#训练回合数\n",
    "epochs = 10\n",
    "#池化大小\n",
    "pool_size = (2, 2)\n",
    "#输入大小\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "# 构建模型\n",
    "model = create_model(input_shape, pool_size)\n",
    "\n",
    "# 构建数据生成器实现通道增强\n",
    "datagen = ImageDataGenerator(channel_shift_range=0.2)\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='Adam', loss='mean_squared_error')\n",
    "# 可视化模型\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4)训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ma-user/anaconda3/envs/TensorFlow-1.13-gpu/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "90/89 [==============================] - 12s 128ms/step - loss: 0.0539 - val_loss: 0.0251\n",
      "Epoch 2/10\n",
      "90/89 [==============================] - 6s 70ms/step - loss: 0.0164 - val_loss: 0.0149\n",
      "Epoch 3/10\n",
      "90/89 [==============================] - 6s 68ms/step - loss: 0.0123 - val_loss: 0.0103\n",
      "Epoch 4/10\n",
      "90/89 [==============================] - 6s 69ms/step - loss: 0.0103 - val_loss: 0.0093\n",
      "Epoch 5/10\n",
      "90/89 [==============================] - 6s 68ms/step - loss: 0.0094 - val_loss: 0.0087\n",
      "Epoch 6/10\n",
      "90/89 [==============================] - 6s 68ms/step - loss: 0.0087 - val_loss: 0.0076\n",
      "Epoch 7/10\n",
      "90/89 [==============================] - 6s 68ms/step - loss: 0.0084 - val_loss: 0.0075\n",
      "Epoch 8/10\n",
      "90/89 [==============================] - 6s 68ms/step - loss: 0.0081 - val_loss: 0.0070\n",
      "Epoch 9/10\n",
      "90/89 [==============================] - 6s 68ms/step - loss: 0.0078 - val_loss: 0.0069\n",
      "Epoch 10/10\n",
      "90/89 [==============================] - 6s 67ms/step - loss: 0.0075 - val_loss: 0.0062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7ab0887f50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size), steps_per_epoch=len(X_train)/batch_size,\n",
    "epochs=epochs, verbose=1, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5)保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze layers since training is done\n",
    "model.trainable = False\n",
    "model.compile(optimizer='Adam', loss='mean_squared_error')\n",
    "\n",
    "# Save model architecture and weights\n",
    "model.save('full_CNN_model_tiny.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 加载并使用模型\n",
    "\n",
    "#### 1） 加载Python相关组件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL.Image import Image\n",
    "from keras.models import load_model\n",
    "from IPython.display import clear_output, Image, display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2）定义工具类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 道路线类\n",
    "class Lanes():\n",
    "    def __init__(self):\n",
    "        self.recent_fit = []\n",
    "        self.avg_fit = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#图像显示方法\n",
    "def arrayShow(imageArray):\n",
    "    ret, jpg = cv2.imencode('.jpg', imageArray)\n",
    "    return Image(jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3）加载检测模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载模型full_CNN_model_tiny.h5\n",
    "model = load_model('full_CNN_model_tiny.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4）读取视频文件和输出检测结果\n",
    "\n",
    "读取input目录下的demo.mp4文件，逐帧读取并交给模型进行检测和识别，然后对检测结果计算其均值，并将检测结果绘制输出。\n",
    "\n",
    "代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] cleaning up...\n"
     ]
    }
   ],
   "source": [
    "#读取视频文件\n",
    "vs = cv2.VideoCapture(\"车道线视频.mp4\")\n",
    "\n",
    "frameIndex = 0\n",
    "\n",
    "lanes = Lanes()\n",
    "\n",
    "#循环读取\n",
    "while True:\n",
    "    #读取视频帧\n",
    "    (grabbed, frame_source) = vs.read()\n",
    "    if not grabbed:\n",
    "        break\n",
    "    \n",
    "    #将视频帧resize为模型的输入大小\n",
    "    frame_show = cv2.resize(frame_source, (576, 288))\n",
    "    frame = cv2.resize(frame_show, (160, 80))\n",
    "\n",
    "\n",
    "    rgb_small_frame = frame[None,:,:,:]\n",
    "\n",
    "   \n",
    "    # 模型推理检测\n",
    "    prediction = model.predict(rgb_small_frame)[0] * 255\n",
    "\n",
    "    # 储存预测结果到列表中\n",
    "    lanes.recent_fit.append(prediction)\n",
    "    # 只使用最近的数据\n",
    "    if len(lanes.recent_fit) > 5:\n",
    "        lanes.recent_fit = lanes.recent_fit[1:]\n",
    "\n",
    "    # 计算平均预测结果\n",
    "    lanes.avg_fit = np.mean(np.array([i for i in lanes.recent_fit]), axis = 0)\n",
    "\n",
    "    # Generate fake R & B color dimensions, stack with G\n",
    "    blanks = np.zeros_like(lanes.avg_fit).astype(np.uint8)\n",
    "    lane_drawn = np.dstack((blanks, lanes.avg_fit, blanks))\n",
    "    \n",
    "    #恢复成原始视频大小\n",
    "    lane_image = cv2.resize(lane_drawn, (576, 288))\n",
    "\n",
    "    #合并原始图像和检测结果\n",
    "    img = cv2.addWeighted(frame_show, 0.3, lane_image, 0.7, 0,dtype = cv2.CV_32F) \n",
    "\n",
    "    \n",
    "    # 清空绘图空间\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    # 显示处理结果\n",
    "    display(arrayShow(img))\n",
    "\n",
    "    #按键盘中的q键退出检测\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# 释放资源\n",
    "print(\"[INFO] cleaning up...\")\n",
    "vs.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 上述的网络model在车道线检测的时候效果并不稳定，所以对其进行了改进。\n",
    "###### 1.增加了网络的层数，修改了每层卷积核的个数。\n",
    "###### 2.受Unet网络的启发，采用并联跳跃结构将encoding的feature map 与 decoding的feature map进行连接，这样可以在进行分类预测时利用多层信息。\n",
    "###### 3.将UpSampling2D改为Conv2DTranspose实现上采样的过程，UpSampling2D直接采用原像素值进行填补不存在学习的过程，而Conv2DTranspose存在学习的过程，效果更好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "718/717 [==============================] - 23s 32ms/step - loss: 0.0364 - val_loss: 0.0125\n",
      "Epoch 2/15\n",
      "718/717 [==============================] - 19s 26ms/step - loss: 0.0080 - val_loss: 0.0113\n",
      "Epoch 3/15\n",
      "718/717 [==============================] - 19s 26ms/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 4/15\n",
      "718/717 [==============================] - 18s 26ms/step - loss: 0.0040 - val_loss: 0.0237\n",
      "Epoch 5/15\n",
      "718/717 [==============================] - 19s 26ms/step - loss: 0.0037 - val_loss: 0.0053\n",
      "Epoch 6/15\n",
      "718/717 [==============================] - 18s 26ms/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 7/15\n",
      "718/717 [==============================] - 18s 26ms/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 8/15\n",
      "718/717 [==============================] - 18s 26ms/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 9/15\n",
      "718/717 [==============================] - 18s 26ms/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 10/15\n",
      "718/717 [==============================] - 19s 26ms/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 11/15\n",
      "718/717 [==============================] - 18s 26ms/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 12/15\n",
      "718/717 [==============================] - 19s 26ms/step - loss: 0.0020 - val_loss: 0.0053\n",
      "Epoch 13/15\n",
      "718/717 [==============================] - 19s 26ms/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 14/15\n",
      "718/717 [==============================] - 18s 26ms/step - loss: 0.0017 - val_loss: 0.0087\n",
      "Epoch 15/15\n",
      "718/717 [==============================] - 18s 26ms/step - loss: 0.0016 - val_loss: 0.0019\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 80, 160, 3)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 78, 158, 16)  448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 76, 156, 16)  2320        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 38, 78, 16)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 36, 76, 32)   4640        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 36, 76, 32)   128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 34, 74, 32)   9248        batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 34, 74, 32)   128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 72, 32)   9248        batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 72, 32)   128         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 16, 36, 32)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 14, 34, 64)   18496       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 14, 34, 64)   256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 12, 32, 64)   36928       batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 12, 32, 64)   256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 6, 16, 64)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 4, 14, 128)   73856       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 4, 14, 128)   512         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 2, 12, 128)   147584      batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 2, 12, 128)   512         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 1, 6, 128)    0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 2, 12, 128)   65664       max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2, 12, 256)   0           conv2d_transpose_1[0][0]         \n",
      "                                                                 batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 4, 14, 128)   295040      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 4, 14, 128)   512         conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 6, 16, 64)    73792       batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 6, 16, 64)    256         conv2d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 12, 32, 64)   16448       batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 12, 32, 128)  0           conv2d_transpose_4[0][0]         \n",
      "                                                                 batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, 14, 34, 64)   73792       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 14, 34, 64)   256         conv2d_transpose_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTrans (None, 16, 36, 32)   18464       batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 36, 32)   128         conv2d_transpose_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTrans (None, 32, 72, 32)   4128        batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 32, 72, 64)   0           conv2d_transpose_7[0][0]         \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTrans (None, 34, 74, 32)   18464       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 34, 74, 32)   128         conv2d_transpose_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTrans (None, 36, 76, 16)   4624        batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 36, 76, 16)   64          conv2d_transpose_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_10 (Conv2DTran (None, 38, 78, 16)   2320        batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 38, 78, 16)   64          conv2d_transpose_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_11 (Conv2DTran (None, 76, 156, 16)  1040        batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 76, 156, 16)  64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 76, 156, 32)  0           conv2d_transpose_11[0][0]        \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_12 (Conv2DTran (None, 78, 158, 16)  4624        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 78, 158, 16)  64          conv2d_transpose_12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_13 (Conv2DTran (None, 80, 160, 8)   1160        batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 80, 160, 8)   32          conv2d_transpose_13[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_14 (Conv2DTran (None, 80, 160, 1)   73          batch_normalization_19[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 885,889\n",
      "Trainable params: 0\n",
      "Non-trainable params: 885,889\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Failed to import `pydot`. Please install `pydot`. For example with `pip install pydot`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-0e8c9c9d8edb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;31m# Show summary of model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TensorFlow-1.13-gpu/lib/python3.7/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[0;34m(model, to_file, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0;34m'LR'\u001b[0m \u001b[0mcreates\u001b[0m \u001b[0ma\u001b[0m \u001b[0mhorizontal\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \"\"\"\n\u001b[0;32m--> 132\u001b[0;31m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TensorFlow-1.13-gpu/lib/python3.7/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0m_check_pydot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mdot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rankdir'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TensorFlow-1.13-gpu/lib/python3.7/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpydot\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         raise ImportError(\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;34m'Failed to import `pydot`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0;34m'Please install `pydot`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             'For example with `pip install pydot`.')\n",
      "\u001b[0;31mImportError\u001b[0m: Failed to import `pydot`. Please install `pydot`. For example with `pip install pydot`."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "#import cv2\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "# Import necessary items from Keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Activation, Dropout, UpSampling2D, concatenate, Input\n",
    "from keras.layers import Conv2DTranspose, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import plot_model\n",
    "from keras import regularizers\n",
    " \n",
    "# Load training images\n",
    "train_images = pickle.load(open(\"full_CNN_train.p\", \"rb\" ))\n",
    " \n",
    "# Load image labels\n",
    "labels = pickle.load(open(\"full_CNN_labels.p\", \"rb\" ))\n",
    " \n",
    "# Make into arrays as the neural network wants these\n",
    "train_images = np.array(train_images)\n",
    "labels = np.array(labels)\n",
    " \n",
    " \n",
    " \n",
    "# Normalize labels - training images get normalized to start in the network\n",
    "labels = labels / 255\n",
    " \n",
    "# Shuffle images along with their labels, then split into training/validation sets\n",
    "train_images, labels = shuffle(train_images, labels)\n",
    "# Test size may be 10% or 20%\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_images, labels, test_size=0.1)\n",
    " \n",
    "# Batch size, epochs and pool size below are all paramaters to fiddle with for optimization\n",
    "batch_size = 16\n",
    "epochs = 15\n",
    "pool_size = (2, 2)\n",
    "#input_shape = X_train.shape[1:]\n",
    " \n",
    "### Here is the actual neural network ###\n",
    "# Normalizes incoming inputs. First layer needs the input shape to work\n",
    "#BatchNormalization(input_shape=input_shape)\n",
    "Inputs = Input(batch_shape=(None, 80, 160, 3))\n",
    " \n",
    "# Below layers were re-named for easier reading of model summary; this not necessary\n",
    "# Conv Layer 1\n",
    "Conv1 = Conv2D(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu')(Inputs)\n",
    "Bat1 = BatchNormalization()(Conv1)\n",
    " \n",
    "# Conv Layer 2\n",
    "Conv2 = Conv2D(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu')(Conv1)\n",
    "Bat2 = BatchNormalization()(Conv2)\n",
    " \n",
    "# Pooling 1\n",
    "Pool1 = MaxPooling2D(pool_size=pool_size)(Conv2)\n",
    " \n",
    "# Conv Layer 3\n",
    "Conv3 = Conv2D(32, (3, 3), padding = 'valid', strides=(1,1), activation = 'relu')(Pool1)\n",
    "#Drop3 = Dropout(0.2)(Conv3)\n",
    "Bat3 = BatchNormalization()(Conv3)\n",
    " \n",
    "# Conv Layer 4\n",
    "Conv4 = Conv2D(32, (3, 3), padding = 'valid', strides=(1,1), activation = 'relu')(Bat3)\n",
    "#Drop4 = Dropout(0.5)(Conv4)\n",
    "Bat4 = BatchNormalization()(Conv4)\n",
    " \n",
    "# Conv Layer 5\n",
    "Conv5 = Conv2D(32, (3, 3), padding='valid', strides=(1,1), activation = 'relu')(Bat4)\n",
    "#Drop5 = Dropout(0.2)(Conv5)\n",
    "Bat5 = BatchNormalization()(Conv5)\n",
    " \n",
    "# Pooling 2\n",
    "Pool2 = MaxPooling2D(pool_size=pool_size)(Bat5)\n",
    " \n",
    "# Conv Layer 6\n",
    "Conv6 = Conv2D(64, (3, 3), padding='valid', strides=(1,1), activation = 'relu')(Pool2)\n",
    "#Drop6 = Dropout(0.2)(Conv6)\n",
    "Bat6 = BatchNormalization()(Conv6)\n",
    " \n",
    "# Conv Layer 7\n",
    "Conv7 = Conv2D(64, (3, 3), padding='valid', strides=(1,1), activation = 'relu')(Bat6)\n",
    "#Drop7 = Dropout(0.2)(Conv7)\n",
    "Bat7 = BatchNormalization()(Conv7)\n",
    " \n",
    "# Pooling 3\n",
    "Pool3 = MaxPooling2D(pool_size=pool_size)(Bat7)\n",
    " \n",
    "# Conv Layer 8\n",
    "Conv8 = Conv2D(128, (3, 3), padding='valid', strides=(1,1), activation = 'relu')(Pool3)\n",
    "#Drop8 = Dropout(0.2)(Conv8)\n",
    "Bat8 = BatchNormalization()(Conv8)\n",
    " \n",
    "# Conv Layer 9\n",
    "Conv9 = Conv2D(128, (3, 3), padding='valid', strides=(1,1), activation = 'relu')(Bat8)\n",
    "#Drop9 = Dropout(0.2)(Conv9)\n",
    "Bat9 = BatchNormalization()(Conv9)\n",
    " \n",
    "# Pooling 4\n",
    "Pool4 = MaxPooling2D(pool_size=pool_size)(Bat9)\n",
    " \n",
    " \n",
    "# Upsample 1 to Deconv 1\n",
    "Deconv1 = Conv2DTranspose(128, (2, 2), padding='valid', strides=(2,2), activation = 'relu')(Pool4)\n",
    "#Up1 = UpSampling2D(size=pool_size)(Pool4)\n",
    "Mer1 = concatenate([Deconv1, Bat9], axis=-1)\n",
    " \n",
    "# Deconv 2\n",
    "Deconv2 = Conv2DTranspose(128, (3, 3), padding='valid', strides=(1,1), activation = 'relu')(Mer1)\n",
    "DBat2 = BatchNormalization()(Deconv2)\n",
    " \n",
    "# Deconv 3\n",
    "Deconv3 = Conv2DTranspose(64, (3, 3), padding='valid', strides=(1,1), activation = 'relu')(DBat2)\n",
    "DBat3 = BatchNormalization()(Deconv3)\n",
    " \n",
    "# Upsample 2 to Deconv 4\n",
    "Deconv4 = Conv2DTranspose(64, (2, 2), padding='valid', strides=(2,2), activation = 'relu')(DBat3)\n",
    "#Up2 = UpSampling2D(size=pool_size)(DBat2)\n",
    "Mer2 = concatenate([Deconv4, Bat7], axis=-1)\n",
    " \n",
    "# Deconv 5\n",
    "Deconv5 = Conv2DTranspose(64, (3, 3), padding='valid', strides=(1,1), activation = 'relu')(Mer2)\n",
    "DBat5 = BatchNormalization()(Deconv5)\n",
    " \n",
    "# Deconv 6\n",
    "Deconv6 = Conv2DTranspose(32, (3, 3), padding='valid', strides=(1,1), activation = 'relu')(DBat5)\n",
    "DBat6 = BatchNormalization()(Deconv6)\n",
    " \n",
    "# Upsample 3 to Deconv 7\n",
    "Deconv7 = Conv2DTranspose(32, (2, 2), padding='valid', strides=(2,2), activation = 'relu')(DBat6)\n",
    "#Up3 = UpSampling2D(size=pool_size)(DBat4)\n",
    "Mer3 = concatenate([Deconv7, Bat5], axis=-1)\n",
    " \n",
    "# Deconv 8\n",
    "Deconv8 = Conv2DTranspose(32, (3, 3), padding='valid', strides=(1,1), activation = 'relu')(Mer3)\n",
    "DBat8 = BatchNormalization()(Deconv8)\n",
    " \n",
    "# Deconv 9\n",
    "Deconv9 = Conv2DTranspose(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu')(DBat8)\n",
    "DBat9 = BatchNormalization()(Deconv9)\n",
    " \n",
    "# Deconv 10\n",
    "Deconv10 = Conv2DTranspose(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu')(DBat9)\n",
    "DBat10 = BatchNormalization()(Deconv10)\n",
    " \n",
    "# Upsample 4 to Deconv 11\n",
    "Deconv11 = Conv2DTranspose(16, (2, 2), padding='valid', strides=(2,2), activation = 'relu')(DBat10)\n",
    "#Up4 = UpSampling2D(size=pool_size)(DBat7)\n",
    "Mer4 = concatenate([Deconv11, Bat2], axis=-1)\n",
    " \n",
    "# Deconv 12\n",
    "Deconv12 = Conv2DTranspose(16, (3, 3), padding='valid', strides=(1,1), activation = 'relu')(Mer4)\n",
    "DBat12 = BatchNormalization()(Deconv12)\n",
    " \n",
    "# Deconv 13\n",
    "Deconv13 = Conv2DTranspose(8, (3, 3), padding='valid', strides=(1,1), activation = 'relu')(DBat12)\n",
    "DBat13 = BatchNormalization()(Deconv13)\n",
    " \n",
    "# Final layer - only including one channel so 1 filter\n",
    "Final = Conv2DTranspose(1, (3, 3), padding='same', strides=(1,1), activation = 'relu')(DBat13)\n",
    " \n",
    "### End of network ###\n",
    "model = Model(inputs=Inputs, outputs=Final)\n",
    " \n",
    " \n",
    "# Using a generator to help the model use less data\n",
    "# Channel shifts help with shadows slightly\n",
    "datagen = ImageDataGenerator(channel_shift_range=0.2)\n",
    "datagen.fit(X_train)\n",
    " \n",
    "# Compiling and training the model\n",
    "model.compile(optimizer='Adam', loss='mean_squared_error')\n",
    "model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size), steps_per_epoch=len(X_train)/batch_size,\n",
    "epochs=epochs, verbose=1, validation_data=(X_val, y_val))\n",
    " \n",
    "# Freeze layers since training is done\n",
    "model.trainable = False\n",
    "model.compile(optimizer='Adam', loss='mean_squared_error')\n",
    " \n",
    "# Save model architecture and weights\n",
    "model.save('full_CNN_model_HYe15.h5')\n",
    " \n",
    "# Show summary of model\n",
    "model.summary()\n",
    "#plot_model(model, to_file='model.png')\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四、实验总结\n",
    "\n",
    "本实验基于深度学习算法进行交通车道检测，通过将视频信号进行分帧后交由模型进行检测车道位置信息，并通过图像合成将其检测结合与原视频帧合并可视化输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
